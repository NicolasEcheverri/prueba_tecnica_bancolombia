{"cells":[{"cell_type":"markdown","metadata":{"id":"Ew3BKQKicKpn"},"source":["# Ejecución modelo Bag of words"]},{"cell_type":"code","source":["!pip install jsonlines"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vIYA6bmcndq","executionInfo":{"status":"ok","timestamp":1703213707093,"user_tz":300,"elapsed":5627,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}},"outputId":"c3268a7a-1b85-4788-d950-22ab11f86142"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jsonlines\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.1.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-4.0.0\n"]}]},{"cell_type":"code","source":["!python -m spacy download en_core_web_sm"],"metadata":{"id":"ELYyvW1ec4KK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"C9qVwSEYcKpt","executionInfo":{"status":"ok","timestamp":1703213707316,"user_tz":300,"elapsed":226,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"outputs":[],"source":["import jsonlines\n","import pandas as pd"]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_selection import RFE\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","import spacy\n","from spacy.lang.en import English"],"metadata":{"id":"OAHCqR5ycuj3","executionInfo":{"status":"ok","timestamp":1703213897357,"user_tz":300,"elapsed":417,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from spacy.lang.en.stop_words import STOP_WORDS"],"metadata":{"id":"Dsv8KHSmdZtb","executionInfo":{"status":"ok","timestamp":1703213901342,"user_tz":300,"elapsed":392,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSSLgKBgcgCX","executionInfo":{"status":"ok","timestamp":1703213697556,"user_tz":300,"elapsed":28468,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}},"outputId":"cf7dd9c2-84c9-4d6a-f873-1ccbca253686"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":35,"metadata":{"id":"aik2cC3-cKpw","executionInfo":{"status":"ok","timestamp":1703214821884,"user_tz":300,"elapsed":623,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"outputs":[],"source":["data_path = '/content/drive/MyDrive/prueba_tecnica_bancolombia/Prueba practica/2020_acl_diplomacy/data/'\n","with jsonlines.open(data_path+'train.jsonl', 'r') as reader:\n","    train = list(reader)\n","with jsonlines.open(data_path+'validation.jsonl', 'r') as reader:\n","    valid = list(reader)\n","with jsonlines.open(data_path+'test.jsonl', 'r') as reader:\n","    test = list(reader)"]},{"cell_type":"code","source":["list(STOP_WORDS)[:10], type(STOP_WORDS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTqHXzzNeKOz","executionInfo":{"status":"ok","timestamp":1703214130626,"user_tz":300,"elapsed":298,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}},"outputId":"3ae29be7-3616-4ee2-9e78-07de4dbf0d48"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['otherwise',\n","  'everywhere',\n","  'made',\n","  'whole',\n","  'last',\n","  'his',\n","  'please',\n","  'and',\n","  'since',\n","  'seems'],\n"," set)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","execution_count":33,"metadata":{"id":"olyYBPwHcKpz","executionInfo":{"status":"ok","timestamp":1703214468579,"user_tz":300,"elapsed":339,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"outputs":[],"source":["def log_reg(train, test):\n","    #Convert train data into a vector\n","    vectorizer = CountVectorizer(tokenizer=spacy_tokenizer, stop_words=list(STOP_WORDS), strip_accents = 'unicode')\n","    if TASK == \"SENDER\":\n","        corpus = [message['message'].lower() for message in aggregate(train)]\n","    elif TASK == \"RECEIVER\": #for receivers, drop all missing annotations\n","        corpus = [message['message'].lower() for message in aggregate(train) if message['receiver_annotation'] != \"NOANNOTATION\"]\n","    X = vectorizer.fit_transform(corpus)\n","\n","    #Convert test data into a vector, only based on train vocab\n","    newVec = CountVectorizer(tokenizer=spacy_tokenizer, vocabulary=vectorizer.vocabulary_, stop_words=list(STOP_WORDS), strip_accents = 'unicode')\n","    if TASK == \"SENDER\":\n","        y = newVec.fit_transform([message['message'].lower() for message in aggregate(test)])\n","    elif TASK == \"RECEIVER\": #for receivers, drop all missing annotations\n","        y = newVec.fit_transform([message['message'].lower() for message in aggregate(test) if message['receiver_annotation'] != \"NOANNOTATION\"])\n","\n","    #only used for getting lie/not lie labels\n","    train = convert_to_binary(aggregate(train))\n","    print(\"len(train): \", len(train))\n","    #validation set not used for consistency with neural\n","    test = convert_to_binary(aggregate(test))\n","    print(\"len(test): \", len(test))\n","    train = split_xy(train)\n","    test = split_xy(test)\n","\n","    #append power to the matrix\n","    append_power_x = np.append(X.toarray(), train[0], axis = 1)\n","    append_power_y = np.append(y.toarray(), test[0], axis = 1)\n","\n","    #code to scale features, if power is added as a raw value, not binary feature.  Worse than binary so not sued\n","    #    from sklearn.preprocessing import StandardScaler\n","    #    scaler = StandardScaler()\n","    #    append_power_x = scaler.fit_transform(append_power_x)\n","    #    append_power_y = scaler.fit_transform(append_power_y)\n","\n","    #convert matrix back to sparse format\n","    X = csr_matrix(append_power_x)\n","    y = csr_matrix(append_power_y)\n","\n","    #balanced class weight is important, since otherwise it will only learn majority class\n","    logmodel = LogisticRegression(class_weight = 'balanced', max_iter=1000)\n","\n","\n","#    RFE VERSION.  Worse than log regression and long run time so not used\n","#    rfe = RFE(logmodel, n_features_to_select = 1000, step = 100, verbose = 1)\n","#    rfe = rfe.fit(X, train[1])\n","#    print(rfe.support_)\n","#    print(rfe.ranking_)\n","#    predictions = rfe.predict(y)\n","#    print(rfe.score(y, test[1]))\n","#    print(classification_report(test[1],predictions))\n","\n","    logmodel.fit(X, train[1])\n","    predictions = logmodel.predict(y)\n","    #code to print out top words\n","#    print (\"Examples of words that skew towards a lie are:\")\n","#    for index,a in enumerate(logmodel.coef_[0]):\n","#        if a > 2:\n","#            print(vectorizer.get_feature_names()[index], a)\n","#\n","#    for index,a in enumerate(logmodel.coef_[0]):\n","#        if a < -2:\n","#            print(vectorizer.get_feature_names()[index], a)\n","\n","    print(classification_report(test[1],predictions, digits=3))\n","\n","    return"]},{"cell_type":"code","source":["def is_number(tok):\n","    try:\n","        float(tok)\n","        return True\n","    except ValueError:\n","        return False\n","\n","def spacy_tokenizer(text):\n","    return [tok.text if not is_number(tok.text) else '_NUM_' for tok in nlp(text)]\n","\n","\n","\n","#change the format from list of lists into a single list\n","def aggregate(dataset):\n","    messages = []\n","    rec = []\n","    send = []\n","    power = []\n","    for dialogs in dataset:\n","        messages.extend(dialogs['messages'])\n","        rec.extend(dialogs['receiver_labels'])\n","        send.extend(dialogs['sender_labels'])\n","        #ONLY FOR POWER VERSION\n","        power.extend(dialogs['game_score_delta'])\n","    #print(len(rec), len(send), len(messages))\n","    merged = []\n","    for i, item in enumerate(messages):\n","        merged.append({'message':item, 'sender_annotation':send[i], 'receiver_annotation':rec[i], 'score_delta':int(power[i])})\n","    return merged"],"metadata":{"id":"Gd_1C0JNdmnz","executionInfo":{"status":"ok","timestamp":1703213954540,"user_tz":300,"elapsed":260,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def convert_to_binary(dataset):\n","    binary_data = []\n","    matrix = []\n","    for message in dataset:\n","        #drop the instances that were not annotated\n","        if message['receiver_annotation'] == True or message['receiver_annotation'] == False:\n","            pass\n","        else:\n","            if TASK == \"SENDER\":\n","                pass\n","            elif TASK == \"RECEIVER\":\n","                continue\n","\n","        binary = []\n","\n","        #a severe power skew (a difference of 5 or more supply centers) has the best result\n","        if POWER == \"y\":\n","            if message['score_delta'] > 4:\n","                binary.append(1)\n","            else:\n","                binary.append(0)\n","\n","            if message['score_delta'] < -4:\n","                binary.append(1)\n","            else:\n","                binary.append(0)\n","\n","        if TASK == \"SENDER\":\n","            annotation ='sender_annotation'\n","        elif TASK == \"RECEIVER\":\n","            annotation ='receiver_annotation'\n","        #add class label\n","        if message[annotation] == False:\n","            binary.append(0)\n","        else:\n","            binary.append(1)\n","\n","        binary_data.append(binary)\n","    return binary_data"],"metadata":{"id":"nr5kdQYmdfZb","executionInfo":{"status":"ok","timestamp":1703213980270,"user_tz":300,"elapsed":387,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#split up x and y label in data\n","def split_xy(data):\n","    X, y = [], []\n","    for line in data:\n","        x = line[:len(line)-1]\n","        single_y = line[len(line)-1]\n","        X.append(x)\n","        y.append(single_y)\n","    return(X, y)"],"metadata":{"id":"Wq37JzNQdtd8","executionInfo":{"status":"ok","timestamp":1703213989712,"user_tz":300,"elapsed":307,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["TASK = \"SENDER\"\n","POWER = \"N\"\n","nlp = English()\n"],"metadata":{"id":"L6dMh66jd4zg","executionInfo":{"status":"ok","timestamp":1703214165135,"user_tz":300,"elapsed":308,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["log_reg(train, test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOh7vMmudvxy","executionInfo":{"status":"ok","timestamp":1703214477771,"user_tz":300,"elapsed":4798,"user":{"displayName":"Nicolas Echeverri","userId":"02711316070982376489"}},"outputId":"5a62cd86-c2cf-48b4-98c5-9b7aa84ba5c6"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\", 'd', 'll', 'm', 've', '‘', '’'] not in stop_words.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:1380: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["len(train):  13132\n","len(test):  2741\n","              precision    recall  f1-score   support\n","\n","           0      0.149     0.242     0.185       240\n","           1      0.923     0.868     0.895      2501\n","\n","    accuracy                          0.813      2741\n","   macro avg      0.536     0.555     0.540      2741\n","weighted avg      0.855     0.813     0.832      2741\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"42BWrVnOfl1_"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}